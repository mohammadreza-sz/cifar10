{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number = 8\n",
    "csv_file ='model_feature_info.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot accuracy and loss graphs\n",
    "def plot_history(history):\n",
    "    fig, axs = plt.subplots(2, figsize=(10, 10))\n",
    "\n",
    "    # Plot accuracy\n",
    "    axs[0].plot(history.history['accuracy'], label='train_accuracy')\n",
    "    axs[0].plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    axs[0].set_title('Accuracy')\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot loss\n",
    "    axs[1].plot(history.history['loss'], label='train_loss')\n",
    "    axs[1].plot(history.history['val_loss'], label='val_loss')\n",
    "    axs[1].set_title('Loss')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'model number {model_number}.png')\n",
    "    plt.show()\n",
    "\n",
    "def write_into_csv(model_params):\n",
    "    #add extra info into end of model info in csv file\n",
    "    x = 0\n",
    "    with open(csv_file, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # Write top-level key-value pairs\n",
    "        for key, value in model_params.items():\n",
    "            if x == 0:\n",
    "              writer.writerow([key, value])\n",
    "              x+=1\n",
    "            elif not isinstance(value, dict):  # Check if value is not a dictionary\n",
    "                writer.writerow([key, value])\n",
    "            else:  # Handle nested dictionary (data_augmentation)\n",
    "                for inner_key, inner_value in value.items():\n",
    "                    writer.writerow([key + '/' + inner_key, inner_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number = int(input(\"enter your last model number: \"))\n",
    "answer_data_augmentation = input('do you want data augmentation:y/n')\n",
    "answer_one_hot = input('do you want one hot? :y/n')\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "model_number+=1\n",
    "\n",
    "write_into_csv({' ':' ','model number':model_number})\n",
    "\n",
    "data_augmentation_params = {\n",
    "    \"vertical_flip\": True,\n",
    "    \"rotation_range\": 20,\n",
    "    \"zoom_range\": 0.2,\n",
    "    \"width_shift_range\":0.1,\n",
    "    \"height_shift_range\":0.1,\n",
    "    \"horizontal_flip\":True\n",
    "}\n",
    "model_params = {\n",
    "    \"activation_functions\": [\"relu\",\"relu\",\"relu\",\"relu\",\"relu\",\"relu\",\"relu\",\"softmax\"],\n",
    "    \"batch_size\": 32  ,\n",
    "    \"epochs\": 200,\n",
    "    \"callbacks\": {\n",
    "        \"EarlyStopping\": {\"monitor\": \"val_loss\", \"patience\": 15},\n",
    "        \"ModelCheckpoint\": {\"filepath\": \"model_checkpoint.keras\", \"save_best_only\": True, \"monitor\": \"val_loss\", \"verbose\": 1},\n",
    "        \"CSVLogger\":{\"filename\":csv_file,\"separator\":\",\",\"append\":\"True\"}\n",
    "    }\n",
    "}\n",
    "# Reduce pixel values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# One-hot encode labels (optional, depending on loss function)\n",
    "number_of_output_class = 10\n",
    "if answer_one_hot =='y':\n",
    "  y_train = tf.keras.utils.to_categorical(y_train, number_of_output_class)\n",
    "  y_test = tf.keras.utils.to_categorical(y_test, number_of_output_class)\n",
    "else:  \n",
    "  # flatten the label values\n",
    "  y_train, y_test = y_train.flatten(), y_test.flatten()\n",
    "\n",
    "\n",
    "\n",
    "# Build a simple Convolutional Neural Network (CNN)\n",
    "# model = Sequential([\n",
    "#     Conv2D(32, (3, 3), activation=model_params['activation_functions'][0], input_shape=(32, 32, 3)),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Conv2D(64, (3, 3), activation=model_params['activation_functions'][1]),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Conv2D(64, (3, 3),  activation=model_params['activation_functions'][2]),\n",
    "#     Flatten(),\n",
    "#     Dense(64,  activation=model_params['activation_functions'][3]),\n",
    "#     Dense(10,  activation=model_params['activation_functions'][4])\n",
    "# ])\n",
    "# model = keras.Sequential(\n",
    "#     [\n",
    "#         keras.layers.Input(shape=(32, 32, 3)),\n",
    "#         keras.layers.Conv2D(32, kernel_size=(3, 3), activation=model_params['activation_functions'][0]),\n",
    "#         keras.layers.Conv2D(32, kernel_size=(3, 3), activation=model_params['activation_functions'][1]),\n",
    "#         keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         keras.layers.Conv2D(64, kernel_size=(3, 3), activation=model_params['activation_functions'][2]),\n",
    "#         keras.layers.Conv2D(64, kernel_size=(3, 3), activation=model_params['activation_functions'][3]),\n",
    "#         keras.layers.GlobalAveragePooling2D(),\n",
    "#         keras.layers.Dropout(0.5),\n",
    "#         keras.layers.Dense(number_of_output_class, activation=model_params['activation_functions'][4]),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# number of classes\n",
    "# K = len(set(y_train))\n",
    "K = number_of_output_class\n",
    " \n",
    "# Build the model using the functional API\n",
    "# input layer\n",
    "i = Input(shape=x_train[0].shape)\n",
    "x = Conv2D(32, (3, 3), activation=model_params['activation_functions'][0], padding='same')(i)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3, 3), activation=model_params['activation_functions'][1], padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    " \n",
    "x = Conv2D(64, (3, 3), activation=model_params['activation_functions'][2], padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3, 3), activation=model_params['activation_functions'][3], padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    " \n",
    "x = Conv2D(128, (3, 3), activation=model_params['activation_functions'][4], padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (3, 3), activation=model_params['activation_functions'][5], padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    " \n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    " \n",
    "# Hidden layer\n",
    "x = Dense(1024, activation=model_params['activation_functions'][6])(x)\n",
    "x = Dropout(0.2)(x)\n",
    " \n",
    "# last hidden layer i.e.. output layer\n",
    "x = Dense(K, activation=model_params['activation_functions'][7])(x)\n",
    " \n",
    "model = Model(i, x)\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(**model_params['callbacks']['EarlyStopping']),\n",
    "    tf.keras.callbacks.ModelCheckpoint(**model_params['callbacks']['ModelCheckpoint']),\n",
    "    # tf.keras.callbacks.ReduceLROnPlateau(**model_params['callbacks']['ReduceLROnPlateau']),\n",
    "    # tf.keras.callbacks.LearningRateScheduler(**model_params['callbacks']['LearningRateScheduler']),\n",
    "    tf.keras.callbacks.CSVLogger(**model_params['callbacks']['CSVLogger']),\n",
    "    tf.keras.callbacks.TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# Compile the model\n",
    "if answer_one_hot =='y':\n",
    "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "else:\n",
    "  model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "if answer_data_augmentation =='y':\n",
    "  model_params[\"data_augmentation\"] = data_augmentation_params\n",
    "  # datagen = ImageDataGenerator(**model_params['data_augmentation'])\n",
    "  data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "  rotation_range = 20, zoom_range = 0.2 ,width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True,vertical_flip= True,)\n",
    "  train_generator = data_generator.flow(x_train, y_train, model_params['batch_size'])\n",
    "  steps_per_epoch = x_train.shape[0] // model_params['batch_size']\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "if answer_data_augmentation =='y':\n",
    "  # history = model.fit(datagen.flow(x_train, y_train, batch_size=model_params['batch_size']), epochs=model_params['epochs'], validation_data=(x_test, y_test) , callbacks=callbacks)\n",
    "  history= model.fit(train_generator,   ,\n",
    "              steps_per_epoch=steps_per_epoch, epochs=model_params['epochs'], callbacks=callbacks)\n",
    "else:\n",
    "  history = model.fit(x_train, y_train, batch_size=model_params['batch_size'], epochs=model_params['epochs'], validation_data=(x_test, y_test) , callbacks=callbacks)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "best_val_acc = max(history.history['val_accuracy'])\n",
    "best_val_loss=min(history.history['val_loss'])\n",
    "print(f\"best Test accuracy: {best_val_acc} ,best test loss :{best_val_loss} \")\n",
    "write_into_csv({\"best test accuracy\":best_val_acc,\"best test loss\":best_val_loss,\"elapsed time\":elapsed_time})\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "#plot train/val for loss/accuracy\n",
    "plot_history(history)\n",
    "write_into_csv(model_params)\n",
    "\n",
    "#write layer info (flatten or conv2d or maxpooling or ...)\n",
    "for layer in model.layers:\n",
    "  layer_info = {\n",
    "  f\"Layer Type\":f\" {type(layer).__name__}\",\n",
    "  f\"Output Shape\":f\" {layer.output_shape}\",\n",
    "  f\"Number of Parameters\":f\"{layer.count_params()}\",\n",
    "  }\n",
    "  write_into_csv(layer_info)\n",
    "model.save('MY_MODEL.keras')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
